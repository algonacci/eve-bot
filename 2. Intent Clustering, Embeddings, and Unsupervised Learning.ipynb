{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intent Clustering, Document Embeddings, and Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I take the preprocessed and tokenized data in the previous notebook and try to assign labels for each Tweet in the dataset by using meaningful document embedding methods and unsupervised learning methods such as K-Means, DBScan, and LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas: 1.0.1\n",
      "Numpy: 1.18.1\n"
     ]
    }
   ],
   "source": [
    "# We need more packages!\n",
    "# Data science\n",
    "import pandas as pd\n",
    "print(f\"Pandas: {pd.__version__}\")\n",
    "import numpy as np\n",
    "print(f\"Numpy: {np.__version__}\")\n",
    "# Unsupervised Learning\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from zeugma.embeddings import EmbeddingTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "# Visualization \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "# Word Embeddings\n",
    "import gensim\n",
    "print(f'gensim: {gensim.__version__}')\n",
    "# Storing as objects via serialization\n",
    "from tempfile import mkdtemp\n",
    "# Cool progress bars\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "tqdm().pandas()  # Enable tracking of execution progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previewing the current data we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_grand.pkl      wcss-kmeans.pkl\r\n",
      "processed_inbound.pkl wcss_grand.pkl\r\n"
     ]
    }
   ],
   "source": [
    "!ls objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b25058221435>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading in the already saved processed dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprocessed_inbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'processed_inbound.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading in the already saved processed dataset\n",
    "processed_inbound = pd.read_pickle('processed_inbound.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38343    [ever, since, late, watch, o, update, get, not...\n",
       "26943    [work, apple, support, get, result, paid, deve...\n",
       "18403    [many, stupid, bug, new, update, ready, throw,...\n",
       "19883    [take, 7, plus, charger, get, ready, work, tim...\n",
       "87560    [log, itunes, account, lap-fucking-top, god, g...\n",
       "Name: inbound_text, dtype: object"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We start with this data, here's the preview\n",
    "processed_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39227    [possibile, save, photo, dropbox, photo, app, ...\n",
       "96901    [can, not, seem, make, genius, bar, appt, onli...\n",
       "32619    [swear, ..., 3rd, io, update, make, iphone, ba...\n",
       "71706    [phone, tell, wifi, password, network, wrong, ...\n",
       "478      [wire, thing, update, 6, gig, available, 10, k...\n",
       "Name: inbound_text, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cachedir = mkdtemp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We give our estimators as a list of tuples: name:function.\n",
    "estimators = [('embedding', EmbeddingTransformer()),\n",
    "              ('model', KMeans())]\n",
    "\n",
    "pipe = Pipeline(estimators, memory = cachedir)\n",
    "\n",
    "params = [\n",
    "    {'embedding': [EmbeddingTransformer()], 'model': [KMeans()],\n",
    "    'embedding__model':['glove'],'model__n_cluster': [8]},\n",
    "    {'embedding':[EmbeddingTransformer()], 'model': [LatentDirichletAllocation()],\n",
    "    'embedding_model':['glove']}\n",
    "]\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittedgrid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding and Vectorizing in a Meaningful Way\n",
    "\n",
    "It is incredibly important to be able to represent this text data as in a meaningful way as to have similar Tweets have closer distances than different Tweets that have different intents. However, since I am working with sequences, I could not just embed their individual words because that will result in a different dimensionality for every single Tweet, and this is something that unsupervised learning algorithms do not know how to handle.\n",
    "\n",
    "Some of these document embedding methods are:\n",
    "* BERT\n",
    "* FastText\n",
    "* Doc2Vec\n",
    "* Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Count Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The easiest way to represent a document as a vector is with a bagofwords CountVectorizer. This will turn each document to be a 1D array, which I think is a good starting point for putting into my clustering algorithms. Let's see how it does. \n",
    "\n",
    "The count vectorizer only accepts the Series if the document is represented as a String, not a tokenized list. So I do that change here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "786e3c64f1574dbd99475f7a44127f96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=52659.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3308cf0435cd4f6f9599b43eb1664b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=25951.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Representing my tokenized data as String documents and storing it into a variable\n",
    "string_processed_X_train = processed_X_train.progress_apply(\" \".join)\n",
    "string_processed_X_test = processed_X_test.progress_apply(\" \".join)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I set the min_df paramater to 5 to only include terms that occur more than 5 times in my Count Vectorized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38343    ever since late watch o update get notificatio...\n",
       "26943    work apple support get result paid development...\n",
       "18403    many stupid bug new update ready throw iphone ...\n",
       "19883    take 7 plus charger get ready work time get ca...\n",
       "87560    log itunes account lap-fucking-top god green e...\n",
       "                               ...                        \n",
       "33943    can not connect disconnect movie anywhere acco...\n",
       "92303    hey put manual fix ️ use word ️ phone funny th...\n",
       "6618     apple watch 3 work caribbean prepare cruise ne...\n",
       "90430    reason phone keep glitching crash reset 7 plus...\n",
       "29828    fix screen recorder like stop record sound som...\n",
       "Name: inbound_text, Length: 52659, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_processed_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39227    possibile save photo dropbox photo app mean ap...\n",
       "96901    can not seem make genius bar appt online wife ...\n",
       "32619      swear ... 3rd io update make iphone bad bad bad\n",
       "71706    phone tell wifi password network wrong phone n...\n",
       "478              wire thing update 6 gig available 10 know\n",
       "                               ...                        \n",
       "57009          get ️ emoji fix letter ️ get together apple\n",
       "96688    iphone let use wifi imessage facetime app stor...\n",
       "189      hey wonder new update phone go banana day far ...\n",
       "79685                take week change password get old one\n",
       "11767    since update io 11 camera work 🙄 anybody else ...\n",
       "Name: inbound_text, Length: 25951, dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string_processed_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52659x4181 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 532614 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vectorizing the data with Count Vectorizer\n",
    "bagofwords = CountVectorizer(min_df = 5).fit(string_processed_X_train)\n",
    "X_train_cv = bagofwords.transform(string_processed_X_train)\n",
    "X_train_cv # Output will be a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's visualize and do what we did earlier and view the top 10 most frequent words in my processed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells me most of the customer queries are about phones, particularly iOS and battery fixes. We also see thanks rank quite high, which is a good thing because it might indicate gratitude (which indicates a closing intent for my chatbot). Hi (rank 44) and hey (rank 25) classifies a greeting intent, and it's good to see that they appear a lot of times. Things are looking promising right now, but we wouldn't be able to see the quality until we actually start clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=5, ngram_range=(1, 3), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, ngram_range = (1,3))\n",
    "tfidf.fit(processed_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing tfidf data and transforming them into sparse matrices\n",
    "X_train_tfidf = tfidf.transform(processed_X_train)\n",
    "X_test_tfidf = tfidf.transform(processed_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52659x23422 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 848948 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25951x23422 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 407769 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained word embeddings\n",
    "Useful source: https://towardsdatascience.com/a-beginners-guide-to-word-embedding-with-gensim-word2vec-model-5970fa56cc92\n",
    "\n",
    "* https://pypi.org/project/zeugma/0.41/\n",
    "* https://github.com/nkthiebaut/zeugma\n",
    "\n",
    "Bag of words lose many of the subtleties such as word ordering. This is why I will try these other text vectorization methods:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GloVe\n",
    "I am going to use multiple word embeddings to vectorize my text in different ways, and then test which one is the best word embedding to use, starting with the Glove word embedding. GloVe is an unsupervised learning algorithm for getting vector representations for words.\n",
    "\n",
    "However, as a disclaimer, I won't be using this one because my clustering algorithms only work when each tweet is one point, and this is  a word transformer. I am leaving this part in my notebook as a progress log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = EmbeddingTransformer('glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717c73cdf973456bba15dd8cc6e83278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63412.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Applying it to the entire training data\n",
    "X_train_glove = processed_X_train.progress_apply(glove.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8130621 , 0.5656479 , 0.6877206 , 0.86405647, 0.64206785,\n",
       "        0.8817774 , 0.73349965, 0.48393366, 0.35663372, 0.6771863 ,\n",
       "        0.86187154, 0.42652112, 0.6414212 , 0.4901102 ],\n",
       "       [0.8943309 , 0.54043406, 0.7118227 , 0.9206827 , 0.7442706 ,\n",
       "        0.88108957, 0.8326488 , 0.55309945, 0.52669424, 0.73307854,\n",
       "        0.89418006, 0.56818885, 0.5923007 , 0.5121745 ],\n",
       "       [0.71216136, 0.7541538 , 0.7458268 , 0.64471316, 0.73993534,\n",
       "        0.592138  , 0.6949012 , 0.7711556 , 0.5190994 , 0.8070698 ,\n",
       "        0.81427187, 0.64189667, 0.7493244 , 0.35251677],\n",
       "       [0.8264686 , 0.6154053 , 0.7340815 , 0.8245878 , 0.6410612 ,\n",
       "        0.8773806 , 0.6969551 , 0.5448388 , 0.33315665, 0.7115154 ,\n",
       "        0.92361647, 0.40779543, 0.641692  , 0.3772235 ],\n",
       "       [0.16007815, 0.36551693, 0.18245363, 0.15790792, 0.21499912,\n",
       "        0.26659784, 0.23867299, 0.09836231, 0.16759305, 0.1912168 ,\n",
       "        0.2684987 , 0.12097125, 0.35895252, 0.08930411],\n",
       "       [0.65246534, 0.63552326, 0.72683483, 0.5499292 , 0.6522421 ,\n",
       "        0.6001457 , 0.56252784, 0.6197041 , 0.38344058, 0.6146572 ,\n",
       "        0.6733852 , 0.4466278 , 0.7552353 , 0.28593874],\n",
       "       [0.8967213 , 0.6205957 , 0.7580144 , 0.947188  , 0.6469538 ,\n",
       "        0.9161521 , 0.8364395 , 0.49175507, 0.5156362 , 0.7424523 ,\n",
       "        0.87512404, 0.5293709 , 0.61857057, 0.34315076],\n",
       "       [0.5597845 , 0.41088822, 0.33966395, 0.54143256, 0.45323205,\n",
       "        0.45865473, 0.56720924, 0.2696702 , 0.5673551 , 0.38699797,\n",
       "        0.36261314, 0.4401882 , 0.6480466 , 0.3681282 ],\n",
       "       [0.35917297, 0.1446432 , 0.20295194, 0.22465847, 0.20799957,\n",
       "        0.08577942, 0.2537207 , 0.3856248 , 0.3010445 , 0.17381155,\n",
       "        0.16686493, 0.40567505, 0.0213764 , 0.02042678],\n",
       "       [0.6371635 , 0.288616  , 0.38890117, 0.69355804, 0.36434546,\n",
       "        0.67433923, 0.45335734, 0.20916812, 0.21356243, 0.32224226,\n",
       "        0.66630125, 0.20628548, 0.27831185, 0.30484468],\n",
       "       [0.83696574, 0.57988876, 0.7325578 , 0.8519593 , 0.5145118 ,\n",
       "        0.99999994, 0.73769265, 0.4425316 , 0.3969484 , 0.601235  ,\n",
       "        0.8606307 , 0.354932  , 0.6177646 , 0.48741272],\n",
       "       [0.91583014, 0.5781672 , 0.66211003, 0.99999994, 0.66983205,\n",
       "        0.8519593 , 0.8573473 , 0.4943112 , 0.5406765 , 0.7318745 ,\n",
       "        0.82574415, 0.57239014, 0.55928767, 0.3753523 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.8442787 , 0.6509677 , 0.7873085 , 0.8062311 , 0.67299956,\n",
       "        0.9010858 , 0.733271  , 0.59263927, 0.48736224, 0.6566994 ,\n",
       "        0.898009  , 0.50104225, 0.6148189 , 0.4612235 ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.34554502, 0.42371595, 0.50596863, 0.30399954, 0.2797027 ,\n",
       "        0.491489  , 0.43276298, 0.37232012, 0.39028472, 0.34751546,\n",
       "        0.3886853 , 0.31689498, 0.45259675, 0.5501409 ],\n",
       "       [0.8335583 , 0.45493677, 0.76711655, 0.80330104, 0.67537427,\n",
       "        0.84475404, 0.678353  , 0.5273182 , 0.36443424, 0.6161037 ,\n",
       "        0.8796177 , 0.39146346, 0.5233237 , 0.41226947],\n",
       "       [0.49837494, 0.42583916, 0.5298627 , 0.49373454, 0.42084524,\n",
       "        0.64727324, 0.34955892, 0.28476918, 0.14214478, 0.24206361,\n",
       "        0.60543376, 0.0958647 , 0.43027318, 0.35824656],\n",
       "       [0.7602564 , 0.59149766, 0.73386604, 0.7041374 , 0.65656006,\n",
       "        0.7084571 , 0.66995   , 0.53285736, 0.5015694 , 0.55294925,\n",
       "        0.7228865 , 0.51333463, 0.61642796, 0.31117594]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(X_train_glove.iloc[0],X_train_glove.iloc[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity could be 0 if they are perpendicular. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10a347bbfa84bbebc69632d1de4418f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=30484.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Doing the same for the testing data\n",
    "X_test_glove = processed_X_test.progress_apply(glove.transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38343    [[0.11597, 0.066013, 0.30173, -0.65542, 0.0217...\n",
       "26943    [[-0.41814, 1.1661, 0.30718, -0.77125, 0.53066...\n",
       "18403    [[1.0472, 0.75721, 0.39005, 0.18197, 0.02607, ...\n",
       "19883    [[-0.39819, 0.92849, 1.1194, -0.13217, -0.2980...\n",
       "87560    [[0.016798, 1.0559, 1.8648, -0.68766, -0.02673...\n",
       "                               ...                        \n",
       "33943    [[0.13191, -0.01726, -0.86139, -0.43648, -1.29...\n",
       "92303    [[-0.011587, 0.6575, 0.19401, 0.1987, -0.69354...\n",
       "6618     [[0.85337, 0.011645, -0.033377, -0.31981, 0.26...\n",
       "90430    [[0.43525, 0.41565, -0.0049016, 0.33494, -0.09...\n",
       "29828    [[0.44877, 1.4266, -0.40778, 0.38396, -0.01416...\n",
       "Name: inbound_text, Length: 63412, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1597e-01,  6.6013e-02,  3.0173e-01, -6.5542e-01,  2.1744e-02,\n",
       "        -4.5297e-01,  2.1000e+00, -1.9427e-01, -1.0320e+00, -6.6347e-01,\n",
       "         3.0398e-01,  4.0125e-01, -4.8677e+00,  1.4501e-01, -2.1228e-01,\n",
       "         1.0987e+00,  6.5365e-01, -3.7288e-01,  1.5131e-01, -6.3025e-01,\n",
       "         2.3052e-01,  6.0988e-01,  1.2155e-01,  4.6332e-01,  2.0091e-01],\n",
       "       [ 5.1860e-02,  8.6367e-01,  1.1402e+00, -7.1556e-01, -1.4073e-01,\n",
       "        -2.6056e-01,  1.0242e+00, -4.3655e-01, -8.5943e-01,  1.0958e-01,\n",
       "        -3.6072e-01,  6.8216e-01, -4.4906e+00,  6.8189e-01,  6.0422e-01,\n",
       "        -1.4920e-01,  3.6563e-01, -2.0704e-01, -8.5323e-02, -6.0814e-01,\n",
       "        -3.2929e-01,  3.5263e-01,  1.9197e-01, -5.5658e-02, -1.6646e-01],\n",
       "       [ 3.4117e-01,  5.1903e-02,  1.3157e-01, -7.7127e-01,  7.1664e-01,\n",
       "        -9.4379e-01,  1.0552e+00, -3.5077e-01,  5.6108e-01, -8.6665e-01,\n",
       "         7.2598e-01,  7.4451e-01, -3.4387e+00,  1.1053e-01,  1.1182e-01,\n",
       "        -5.5985e-01,  6.5788e-01,  2.3376e-01, -5.1038e-01,  9.2750e-02,\n",
       "        -1.1263e+00, -1.1907e+00, -1.7894e-01, -1.0753e+00, -1.1169e+00],\n",
       "       [ 2.7806e-01,  4.2837e-01,  3.8726e-01, -8.2940e-01, -7.5826e-01,\n",
       "        -4.4426e-01,  1.7621e+00,  1.1907e-01,  1.6156e-01, -7.2022e-01,\n",
       "        -4.7905e-01,  6.7888e-01, -4.5780e+00, -1.7566e-01,  7.3636e-02,\n",
       "         2.4484e-01,  3.6114e-01, -3.8957e-01, -4.3863e-01, -9.4151e-02,\n",
       "        -5.2517e-01, -4.4816e-02,  7.8118e-01, -7.1210e-01,  4.7927e-01],\n",
       "       [ 2.9598e+00, -5.4782e-02,  8.5045e-01,  3.8361e-01,  1.3288e-01,\n",
       "        -2.4879e-01, -3.8561e-01,  4.7367e-01, -3.5279e-01, -1.6415e+00,\n",
       "        -1.6796e-03, -3.7109e+00, -2.0034e+00, -3.7925e-01, -2.6033e-01,\n",
       "        -5.6080e-01, -1.0259e+00, -9.2499e-01, -6.0050e-01,  6.7755e-03,\n",
       "        -6.2346e-01,  1.7418e-01,  3.2683e-01,  1.9745e-01,  3.5460e-01],\n",
       "       [ 6.9946e-01,  7.5647e-01,  2.7693e-02, -1.0928e+00,  3.5487e-01,\n",
       "        -6.8115e-01,  1.3262e+00,  1.0372e+00,  1.2488e+00,  5.1408e-01,\n",
       "         6.7335e-01,  1.2216e+00, -2.7238e+00,  5.5478e-02,  2.9960e-01,\n",
       "         2.8995e-01,  2.5090e-01, -1.6582e-01, -9.4264e-01, -4.1924e-01,\n",
       "        -8.6031e-01, -1.0047e+00, -2.4399e-01,  6.1082e-02, -5.9699e-01],\n",
       "       [-3.3344e-01,  1.2678e+00,  4.4720e-02, -6.7070e-01, -2.0790e-01,\n",
       "         1.2289e-01,  1.3696e+00, -2.2981e-01, -5.3645e-01, -1.8330e-01,\n",
       "        -1.3394e-01,  6.3001e-01, -5.6577e+00, -6.6158e-01, -2.6856e-01,\n",
       "        -1.4720e-01,  7.1835e-01, -1.1591e+00, -5.5771e-02, -8.7320e-01,\n",
       "        -2.5146e-02,  3.0690e-01,  1.0787e+00,  3.8923e-01, -2.8963e-02],\n",
       "       [ 8.5676e-01,  8.8132e-01,  7.6881e-01,  4.7229e-02,  1.2712e+00,\n",
       "        -5.0844e-01,  4.2324e-01, -1.3851e+00, -7.0241e-01,  5.4530e-01,\n",
       "        -3.1209e-01,  2.8190e-02, -1.8196e+00, -7.0424e-01, -1.5608e-01,\n",
       "         1.4461e+00,  5.6272e-01, -9.2146e-01, -3.4718e-01, -6.3749e-01,\n",
       "         6.8274e-03, -1.5079e+00,  1.0763e+00,  2.4498e-01, -1.5439e+00],\n",
       "       [-1.2405e+00,  1.9827e-01,  2.8343e-01,  4.3814e-01, -6.0777e-01,\n",
       "        -2.5823e-03, -4.4614e-01, -2.2704e+00,  6.6461e-01, -6.8388e-01,\n",
       "        -6.3567e-01,  2.8096e-01, -7.0264e-01, -5.2373e-01,  2.2646e-01,\n",
       "         1.0028e-01,  1.6950e-01, -3.4255e-01,  2.1996e+00, -9.3890e-01,\n",
       "        -7.3011e-01, -5.8100e-01, -1.1400e+00, -3.9329e-01,  1.1114e-01],\n",
       "       [-9.4296e-01,  1.3406e-01,  2.4230e-01,  1.5744e+00, -2.3682e-01,\n",
       "         3.1562e-01,  1.7821e+00, -9.2026e-01, -4.5905e-02,  5.6448e-01,\n",
       "        -2.0314e-01,  1.0611e+00, -2.8341e+00, -8.0071e-03, -4.7848e-01,\n",
       "         5.0247e-01,  1.3682e-01,  1.5717e-01,  5.4677e-02, -7.7379e-01,\n",
       "         3.2908e-01,  7.8482e-01,  1.4684e+00,  6.5601e-01,  3.1804e-01],\n",
       "       [-2.6079e-01,  5.9108e-01,  6.1622e-01, -7.0368e-01, -8.5159e-01,\n",
       "        -2.3238e-01,  1.0481e+00,  6.6642e-02, -5.4907e-01,  7.0047e-01,\n",
       "        -8.7221e-01, -1.3954e-02, -5.9671e+00, -4.3106e-01, -9.1540e-01,\n",
       "         5.3744e-01,  5.7099e-01, -2.7181e-01, -8.4178e-01, -5.9682e-01,\n",
       "         4.5160e-01,  3.4097e-01,  7.6869e-02,  2.2840e-01,  2.7580e-01],\n",
       "       [-6.9615e-01,  1.1836e+00,  7.1771e-01, -9.8225e-01,  3.5529e-01,\n",
       "         6.8034e-01,  1.2806e+00, -9.0871e-01, -1.1670e+00, -1.2910e-01,\n",
       "         2.7425e-02,  6.7885e-01, -5.0059e+00, -6.2707e-01,  3.7199e-01,\n",
       "        -2.4592e-01,  4.9111e-01, -4.9196e-01,  3.8042e-03, -1.3281e+00,\n",
       "        -3.5287e-02,  5.6014e-01,  7.9602e-01, -7.0036e-02, -4.0572e-01],\n",
       "       [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "       [ 2.8228e-01,  1.9558e-02,  1.1509e-01, -3.9242e-01, -1.0503e+00,\n",
       "        -5.4278e-01,  1.1357e+00, -3.4251e-01,  8.0636e-01, -4.7359e-01,\n",
       "        -7.7194e-01, -7.3689e-01, -6.2619e+00, -3.4902e-01, -3.5532e-01,\n",
       "        -6.0148e-01, -5.4534e-02, -6.7057e-01, -3.9972e-01, -1.3240e+00,\n",
       "        -4.3765e-01,  3.0045e-01,  2.1430e-01,  2.5422e-01, -2.6674e-01],\n",
       "       [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
       "       [-5.3028e-01,  7.8505e-01, -2.7571e-01, -3.0433e-01,  2.1584e-01,\n",
       "        -1.0556e+00, -1.4259e+00,  4.3374e-01,  5.3249e-02,  8.4139e-01,\n",
       "         7.2601e-01, -2.1870e+00, -2.8404e+00,  9.6447e-01, -6.2352e-01,\n",
       "         1.3878e+00, -9.0320e-01,  8.8589e-01, -2.1908e+00, -8.0537e-01,\n",
       "        -9.0784e-01, -2.6988e-01, -8.4029e-02, -4.1868e-01, -6.0060e-01],\n",
       "       [-9.5101e-01,  5.0560e-01,  3.6139e-01, -4.0337e-01, -4.0042e-02,\n",
       "        -1.5647e-01,  2.2782e+00,  2.4500e-01, -4.8452e-01, -1.9628e-01,\n",
       "        -5.1955e-01,  2.1754e-01, -4.7039e+00,  9.5037e-01, -9.8481e-02,\n",
       "        -5.7552e-01,  7.2248e-02, -9.5375e-01, -6.9446e-01, -5.4825e-02,\n",
       "        -8.6766e-01,  2.5728e-02, -2.6051e-01,  7.5546e-01,  4.2688e-01],\n",
       "       [ 6.9586e-01, -1.1469e+00, -4.1797e-01, -2.2311e-02, -2.3801e-02,\n",
       "         8.2358e-01,  1.2228e+00,  1.7410e+00, -9.0979e-01,  1.3725e+00,\n",
       "         1.1530e-01, -6.3906e-01, -3.2252e+00,  6.1269e-01,  3.3544e-01,\n",
       "        -5.7058e-01, -5.0861e-01, -1.6575e-01, -9.8153e-01, -8.2130e-01,\n",
       "         2.4333e-01, -1.4482e-01, -6.7877e-01,  7.0610e-01,  4.0833e-01],\n",
       "       [ 4.4877e-01,  1.4266e+00, -4.0778e-01,  3.8396e-01, -1.4161e-02,\n",
       "         1.7239e-01,  1.0145e+00,  7.8520e-02,  1.0829e+00,  7.5544e-01,\n",
       "         3.7450e-01,  5.2940e-01, -3.1336e+00, -4.4927e-01,  4.2623e-01,\n",
       "         4.0551e-01,  9.1764e-02, -6.1886e-01, -3.1532e-01, -7.6114e-01,\n",
       "        -8.1221e-01,  4.6616e-01,  1.7360e-02,  9.6589e-01, -2.8626e-01]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39227     [[-1.2505, 0.36804, -0.53604, -0.53954, 0.4247...\n",
       "101508    [[0.11597, 0.066013, 0.30173, -0.65542, 0.0217...\n",
       "49484     [[-0.31777, 1.7887, -0.042583, -0.23544, -0.27...\n",
       "6873      [[1.4512, -0.24502, 0.18376, -0.57901, 1.1378,...\n",
       "50704     [[0.3767, 0.036902, -0.79194, -0.57057, 0.8150...\n",
       "                                ...                        \n",
       "57009     [[-0.34366, 1.2638, 1.1414, -0.68691, -0.05408...\n",
       "96688     [[1.4512, -0.24502, 0.18376, -0.57901, 1.1378,...\n",
       "189       [[-0.011587, 0.6575, 0.19401, 0.1987, -0.69354...\n",
       "79685     [[-0.20353, 1.0148, -0.18363, 0.32951, -0.6129...\n",
       "11767     [[0.05186, 0.86367, 1.1402, -0.71556, -0.14073...\n",
       "Name: inbound_text, Length: 31334, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec\n",
    "This is a way that was developed for word2vec to generalize to paragraphs. Doc2Vec takes the average across them, and each tweet is represented as a single embedding, each of length 25 and you have vectors of consistent dimensionality.\n",
    "\n",
    "* https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e\n",
    "* https://radimrehurek.com/gensim/models/doc2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(common_texts)]\n",
    "model = Doc2Vec(documents, vector_size=5, window=2, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import get_tmpfile\n",
    "fname = get_tmpfile(\"my_doc2vec_model\")\n",
    "model.save(fname)\n",
    "model = Doc2Vec.load(fname)  # you can continue training with the loaded model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A summary of the different data I have:\n",
    "* Count vectorized ```X_train_cv, X_test_cv```\n",
    "* Tfidf ```X_train_tfidf, X_test_tfidf```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advice\n",
    "Try to do clustering or topic modelling on this to pull out major themes and manually label these clusters.\n",
    "Different vectorization methods: word2vec (developed using NNs), countvectorizer, tfidf. Up to us for finding the clusters and the quality of the results and infer what the general topic might be.\n",
    "\n",
    "* K-means (most widely used)\n",
    "* DBscan (a bit slower but we don't have to determine the clusters ahead of time)\n",
    "\n",
    "You will have more success if you find one around the same type of domain. If they're all the same domain, they will capture the nuances. Generally the bot is going to be good at conversing topics on the language it's trained on. Maybe once you've trained it to detect a greeting they are more universal. If merge you might have to make your own IDs for this.\n",
    "\n",
    "You can't expect your model to do something and you intepret your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. K Means Approach\n",
    "My first approach for the clustering my word vectors is K-Means, which tends to perform well on blobs.\n",
    "\n",
    "A drawback is that it is very slow, and picking the value for K is hard - I don't even know how many intents there are in the data. This is why I start with larger jumps of K to get a higher level idea of which performs the best, then I dive deeper to finally decide what K works the best for finding the optimal number of intents in my dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 X_train_cv\n",
      "1 X_train_tfidf\n"
     ]
    }
   ],
   "source": [
    "# X_test\n",
    "test_data = {'X_test_cv': X_test_cv, 'X_test_tfidf': X_test_tfidf}\n",
    "\n",
    "# Starting with X_Train\n",
    "vectorized_data = {'X_train_cv': X_train_cv, 'X_train_tfidf': X_train_tfidf}\n",
    "for i,j in enumerate(vectorized_data.items()): print(i,j[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/ipykernel_launcher.py:5: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ba840d0838a40b888af8d390b5d5cdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a7167cc65f64757a4faf05d85738e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently fitting X_train_cv with 10 clusters... Please wait\n",
      "Currently fitting X_train_cv with 20 clusters... Please wait\n",
      "Currently fitting X_train_cv with 30 clusters... Please wait\n",
      "Currently fitting X_train_cv with 40 clusters... Please wait\n",
      "Currently fitting X_train_cv with 50 clusters... Please wait\n",
      "Currently fitting X_train_cv with 60 clusters... Please wait\n",
      "Currently fitting X_train_cv with 70 clusters... Please wait\n",
      "Currently fitting X_train_cv with 80 clusters... Please wait\n",
      "Currently fitting X_train_cv with 90 clusters... Please wait\n",
      "Currently fitting X_train_cv with 100 clusters... Please wait\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7960b55b4251427c8220c033bdfbe119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently fitting X_train_tfidf with 10 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 20 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 30 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 40 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 50 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 60 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 70 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 80 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 90 clusters... Please wait\n",
      "Currently fitting X_train_tfidf with 100 clusters... Please wait\n",
      "\n",
      "\n",
      "CPU times: user 3h 8min 47s, sys: 4min 57s, total: 3h 13min 45s\n",
      "Wall time: 3h 38min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "wcss_grand = {}\n",
    "labels_grand = {}\n",
    "n_clusters = [10,20,30,40,50,60,70,80,90,100]\n",
    "\n",
    "for i,j in tqdm(enumerate(vectorized_data.items())): # Starting with train data\n",
    "    wcss = []\n",
    "    labels = []\n",
    "    for k in tqdm(n_clusters):    \n",
    "        print(f'Currently fitting {j[0]} with {k} clusters... Please wait')\n",
    "        # Initializing with k-means++ ensures that you get don’t fall into the random initialization trap.\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state = 10)\n",
    "        kmeans.fit(vectorized_data[j[0]])\n",
    "        wcss.append(kmeans.inertia_)\n",
    "        labels.append(kmeans.labels_)\n",
    "    # Updating grand dictionary\n",
    "    wcss_grand[j[0] + '_wcss'] = wcss\n",
    "    labels_grand[j[0] + '_labels'] = labels\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing results\n",
    "\n",
    "Wow! It took me three hours to apply K-Means over 10 iterations from 10 to 100 for both data types. Better save my model results in a pkl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train_cv_wcss': [530645.972276302,\n",
       "  515872.56591591635,\n",
       "  506263.25096308935,\n",
       "  499273.0325938495,\n",
       "  494721.5635948987,\n",
       "  490252.59452755644,\n",
       "  485571.38124904723,\n",
       "  483391.18722595525,\n",
       "  480814.251332943,\n",
       "  478320.6774778482],\n",
       " 'X_train_tfidf_wcss': [51187.78134353667,\n",
       "  50629.84828632547,\n",
       "  50215.28652104986,\n",
       "  49864.89596652504,\n",
       "  49569.48339937552,\n",
       "  49331.49470316796,\n",
       "  49092.011408560604,\n",
       "  48905.286083337814,\n",
       "  48707.45932094955,\n",
       "  48543.9464381612]}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcss_grand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train_cv_labels': [array([3, 0, 8, ..., 0, 7, 4], dtype=int32),\n",
       "  array([ 0, 15, 13, ..., 15,  1, 12], dtype=int32),\n",
       "  array([26, 16, 25, ..., 14,  2, 13], dtype=int32),\n",
       "  array([ 3,  8, 19, ...,  8, 32,  2], dtype=int32),\n",
       "  array([ 3,  8, 19, ...,  8, 32, 28], dtype=int32),\n",
       "  array([35, 11,  2, ..., 46, 36, 59], dtype=int32),\n",
       "  array([35, 11,  2, ..., 46, 36, 59], dtype=int32),\n",
       "  array([15, 11,  2, ..., 46, 36, 59], dtype=int32),\n",
       "  array([ 3, 54, 16, ..., 60, 67, 46], dtype=int32),\n",
       "  array([ 3, 54, 90, ..., 60, 67, 46], dtype=int32)],\n",
       " 'X_train_tfidf_labels': [array([8, 4, 3, ..., 4, 3, 1], dtype=int32),\n",
       "  array([ 8, 14,  1, ...,  4,  1, 17], dtype=int32),\n",
       "  array([ 4, 14, 21, ..., 28, 21, 11], dtype=int32),\n",
       "  array([26, 21, 29, ..., 28, 20, 38], dtype=int32),\n",
       "  array([49, 14, 25, ..., 15, 48, 11], dtype=int32),\n",
       "  array([37, 36, 54, ...,  5, 50, 38], dtype=int32),\n",
       "  array([37, 36, 54, ..., 67, 43, 38], dtype=int32),\n",
       "  array([ 0,  7, 77, ..., 22, 72, 19], dtype=int32),\n",
       "  array([80, 36, 54, ..., 67, 74, 34], dtype=int32),\n",
       "  array([17, 43, 69, ..., 20, 24, 58], dtype=int32)]}"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_grand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings.ipynb                     processed_X_train.pkl\r\n",
      "Natural Language Understanding.ipynb ten_clust.csv\r\n",
      "d2v.model                            test.pkl\r\n",
      "\u001b[1m\u001b[36mdata\u001b[m\u001b[m                                 tests.py\r\n",
      "labels_grand.pkl                     wcss-kmeans.pkl\r\n",
      "\u001b[1m\u001b[36mmatt_chatbot\u001b[m\u001b[m                         words_rank.csv\r\n",
      "processed_X_test.pkl                 words_rank_postprocessed.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It took me a while to train this model. I'm going to use scikitlearn's joblib to store this model that I trained so that I don't have to run it multiple times. I also store the dictionaries I stored my results in using Python's serialization package called Pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumping my dictionaries that store the results of my k-means iteration\n",
    "\n",
    "with open('objects/wcss_grand.pkl', 'wb') as handle:\n",
    "    pickle.dump(wcss_grand, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "with open('objects/labels_grand.pkl', 'wb') as handle:\n",
    "    pickle.dump(labels_grand, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing it into objects I can use in this notebook\n",
    "\n",
    "with open('objects/wcss-kmeans.pkl', 'rb') as handle:\n",
    "    wcss_grand = pickle.load(handle)\n",
    "with open('objects/labels_grand.pkl','rb') as handle:\n",
    "    labels_grand = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "In order to compare different clustering methods, I use a silouhette score and did a granular dive into each of the clustered Tweets to try to manually see if one cluster represents a distinct intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X_train_cv_wcss': [530645.972276302,\n",
       "  515872.56591591635,\n",
       "  506263.25096308935,\n",
       "  499273.0325938495,\n",
       "  494721.5635948987,\n",
       "  490252.59452755644,\n",
       "  485571.38124904723,\n",
       "  483391.18722595525,\n",
       "  480814.251332943,\n",
       "  478320.6774778482],\n",
       " 'X_train_tfidf_wcss': [51187.78134353667,\n",
       "  50629.84828632547,\n",
       "  50215.28652104986,\n",
       "  49864.89596652504,\n",
       "  49569.48339937552,\n",
       "  49331.49470316796,\n",
       "  49092.011408560604,\n",
       "  48905.286083337814,\n",
       "  48707.45932094955,\n",
       "  48543.9464381612]}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcss_grand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am making an elbow plot to see if there is a clear elbow, which hopefully I'll find but it's not very likely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Elbow Plot\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.plot(range(10, 101, 10), wcss_grand['X_train_cv_wcss'], color = 'magenta')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing and Comparing Clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the data, then for reproducibility set a random state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For 5 clusters\n",
    "ten_clust = pd.DataFrame({'data': processed_X_train,'original': original, 'labels': labels[6]}).sort_values('labels',ignore_index = True)\n",
    "six_clust = pd.DataFrame({'data': processed_X_train,'labels': labels[3]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>original</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[yep, i, have, thought, app, site, fault, yikes]</td>\n",
       "      <td>@285455 Yep - I've had that too. I thought it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[still, waiting, order, status, change, order,...</td>\n",
       "      <td>Still waiting for my order status to change fr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[using, #ios11, ipadair, 2, conclude, ruined, ...</td>\n",
       "      <td>After a while using #ios11 on my iPadAir2, I c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1st, messages, deleted, pics, gone, wtf, get,...</td>\n",
       "      <td>1st all my messages deleted now all my pics ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[hi, want, view, us, app, store, i, am, uk, on...</td>\n",
       "      <td>@AppleSupport Hi I want to view the US app sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>[help, please, every, time, ️, type, letter, ️...</td>\n",
       "      <td>@AppleSupport Help please every time i️ type t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>[say, 7hrs, .., pretty, awful, ask, :(]</td>\n",
       "      <td>@AppleSupport I’d say about 7hrs.. which is pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>[stop, ️, swearr, tooo, god, sound, bad, atm, ...</td>\n",
       "      <td>IF THIS DOES NOT STOP I️ SWEARR TOOO GOD @1158...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15819</th>\n",
       "      <td>[man, ️, keep, popping, type, letter, comes, h...</td>\n",
       "      <td>Man why do this “ I️  “keep popping up when we...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15820</th>\n",
       "      <td>[made, sure, mac, listed, still, cannot, downl...</td>\n",
       "      <td>@AppleSupport I am. Just made sure my mac is l...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15821 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  \\\n",
       "0       [yep, i, have, thought, app, site, fault, yikes]   \n",
       "1      [still, waiting, order, status, change, order,...   \n",
       "2      [using, #ios11, ipadair, 2, conclude, ruined, ...   \n",
       "3      [1st, messages, deleted, pics, gone, wtf, get,...   \n",
       "4      [hi, want, view, us, app, store, i, am, uk, on...   \n",
       "...                                                  ...   \n",
       "15816  [help, please, every, time, ️, type, letter, ️...   \n",
       "15817            [say, 7hrs, .., pretty, awful, ask, :(]   \n",
       "15818  [stop, ️, swearr, tooo, god, sound, bad, atm, ...   \n",
       "15819  [man, ️, keep, popping, type, letter, comes, h...   \n",
       "15820  [made, sure, mac, listed, still, cannot, downl...   \n",
       "\n",
       "                                                original  labels  \n",
       "0      @285455 Yep - I've had that too. I thought it ...       0  \n",
       "1      Still waiting for my order status to change fr...       0  \n",
       "2      After a while using #ios11 on my iPadAir2, I c...       0  \n",
       "3      1st all my messages deleted now all my pics ar...       0  \n",
       "4      @AppleSupport Hi I want to view the US app sto...       0  \n",
       "...                                                  ...     ...  \n",
       "15816  @AppleSupport Help please every time i️ type t...       0  \n",
       "15817  @AppleSupport I’d say about 7hrs.. which is pr...       0  \n",
       "15818  IF THIS DOES NOT STOP I️ SWEARR TOOO GOD @1158...       0  \n",
       "15819  Man why do this “ I️  “keep popping up when we...       0  \n",
       "15820  @AppleSupport I am. Just made sure my mac is l...       0  \n",
       "\n",
       "[15821 rows x 3 columns]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_clust.to_csv('ten_clust.csv') # Storing to CSV to view results\n",
    "ten_clust[ten_clust['labels'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>original</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15821</th>\n",
       "      <td>[11.1, 2, still, fixed, many, bug, issues, iph...</td>\n",
       "      <td>@AppleSupport 11.1.2 still hasn’t fixed many o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15822</th>\n",
       "      <td>[got, brand, new, iphone, 8, plus, stuck, reco...</td>\n",
       "      <td>I’ve got a brand new @115858 iPhone 8 Plus tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15823</th>\n",
       "      <td>[iphone, 6s, battery, life, completely, crappe...</td>\n",
       "      <td>My iPhone 6S battery life has completely crapp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15824</th>\n",
       "      <td>[iphone, 8, plus, problem, speakers, sound, ev...</td>\n",
       "      <td>@AppleSupport iphone 8 plus I have a problem w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15825</th>\n",
       "      <td>[iphone, 5s, keeps, dying, 40, snapchat, app, ...</td>\n",
       "      <td>@AppleSupport iPhone 5S keeps dying on 40%+ wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22285</th>\n",
       "      <td>[iphone, trippin, mane, cause, want, go, buy, ...</td>\n",
       "      <td>@115858 why my iphone trippin mane, it’s cause...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22286</th>\n",
       "      <td>[tried, see, pic, iphone, x, showing, corner, ...</td>\n",
       "      <td>@AppleSupport I tried that but if you can see ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22287</th>\n",
       "      <td>[wanna, able, change, screen, gestures, iphone...</td>\n",
       "      <td>I wanna be able to change the screen gestures ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22288</th>\n",
       "      <td>[iphone, hangs, lot, ..., really, reason, ...,...</td>\n",
       "      <td>@AppleSupport My iPhone hangs a lot....I reall...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22289</th>\n",
       "      <td>[since, getting, iphone, 8, plus, updating, io...</td>\n",
       "      <td>@AppleSupport why since getting the iPhone 8 P...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6469 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  \\\n",
       "15821  [11.1, 2, still, fixed, many, bug, issues, iph...   \n",
       "15822  [got, brand, new, iphone, 8, plus, stuck, reco...   \n",
       "15823  [iphone, 6s, battery, life, completely, crappe...   \n",
       "15824  [iphone, 8, plus, problem, speakers, sound, ev...   \n",
       "15825  [iphone, 5s, keeps, dying, 40, snapchat, app, ...   \n",
       "...                                                  ...   \n",
       "22285  [iphone, trippin, mane, cause, want, go, buy, ...   \n",
       "22286  [tried, see, pic, iphone, x, showing, corner, ...   \n",
       "22287  [wanna, able, change, screen, gestures, iphone...   \n",
       "22288  [iphone, hangs, lot, ..., really, reason, ...,...   \n",
       "22289  [since, getting, iphone, 8, plus, updating, io...   \n",
       "\n",
       "                                                original  labels  \n",
       "15821  @AppleSupport 11.1.2 still hasn’t fixed many o...       1  \n",
       "15822  I’ve got a brand new @115858 iPhone 8 Plus tha...       1  \n",
       "15823  My iPhone 6S battery life has completely crapp...       1  \n",
       "15824  @AppleSupport iphone 8 plus I have a problem w...       1  \n",
       "15825  @AppleSupport iPhone 5S keeps dying on 40%+ wh...       1  \n",
       "...                                                  ...     ...  \n",
       "22285  @115858 why my iphone trippin mane, it’s cause...       1  \n",
       "22286  @AppleSupport I tried that but if you can see ...       1  \n",
       "22287  I wanna be able to change the screen gestures ...       1  \n",
       "22288  @AppleSupport My iPhone hangs a lot....I reall...       1  \n",
       "22289  @AppleSupport why since getting the iPhone 8 P...       1  \n",
       "\n",
       "[6469 rows x 3 columns]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ten_clust[ten_clust['labels'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ten_clust' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-037e8d1b53ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mten_clust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mten_clust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ten_clust' is not defined"
     ]
    }
   ],
   "source": [
    "ten_clust[ten_clust['labels'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each cluster is specific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means with glove doc2vec embedded vectorized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K Means expects the dimensionality is the same between all elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63412,)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 25)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 19 words, each word is represented by an array of size 25\n",
    "X_train_glove.iloc[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 25)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.iloc[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 25)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.iloc[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19, 25)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_glove.iloc[3].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Means clustering is struggling because you are passing in multiple arrays with different words, and each word has a different vector. Rather than encoding each Tweet with words. Doc2Vec converts the entire document into one vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do you check how it's performing, visualizing with PCA and t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gensim containts pretrained word embeddings and load them in. They have a special data format where you can basically load it in as a numpy array. Word2Vec is a NN architecture which basically trains Word2Vec method to generate word embeddings.\n",
    "\n",
    "Someone has run this on a massive data and released the embeddings the model learned on the internet. Takes in various website and different contexts with learning. When you trained it to learn the words from like academic papers, the meaning of the word it learns is different than general twitter data. But a good thing about the word embeddigns is that they are usualyl trained on pretrained.\n",
    "\n",
    "Glove is another algorithm for calculating word vectors. BERT, etc. Fast text is quite popular as well. You'll get some kind of file with those words and you'll basically generate this word-to-word embedding matrix and you pass it in as the weights layer in your NN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting with K-Means. Use Scikitlearn's tokenizer. Transform the text into vector representation like tfidf or CountVectorizer. You have a matrix of all your rows, you have your pretrained word embeddings, you'll have to manually match up each word with the word vector.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you build NN, when you use K fold it will take a LONG time so you can probably get away without doing CV with your NN and hyperparamater optimization. These embedding transformer has pretrained word embeddings, it will fit the data with that.\n",
    "\n",
    "Do more exploration on your data. Sometimes when you have NLTK on tweets it gets weird. Because they have been trained on actual text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LDA (Latent Dirichlet Allocation)\n",
    "My second approach for the clustering is LDA topic modelling (Latent Dirichlet Allocation). It basically takes your data and splits it into topics. My goal is still to cluster, but with this method I hope to get more useful, distinct topics.\n",
    "\n",
    "Useful article:\n",
    "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For time constraint's sake, I decided not to use DBScan because they will achieve a clustering result similar to K-Means. I could have also use Gaussian Mixed Models or Heirarchical Clustering to achieve this clustering result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "capstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
